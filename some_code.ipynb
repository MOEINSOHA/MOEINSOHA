{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWsT9m7RmdxcdfTTj0gZec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOEINSOHA/MOEINSOHA/blob/main/some_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR MASK ALGORITHM**"
      ],
      "metadata": {
        "id": "VIDMqmnT6cpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0dXzza76Tho"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# upload image\n",
        "input_image_path = \"/content/CellNet/CellNet/Breast_Malignant/SOB_M_DC-14-10926-400-002.png\"\n",
        "image = cv2.imread(input_image_path, 0)  # gray scale\"\n",
        "\n",
        "# OtsuThresholding alogorithm adjust mask\n",
        "thresh_value = threshold_otsu(image)\n",
        "binary_mask = image > thresh_value\n",
        "\n",
        "# use morphologhic data\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "binary_mask = cv2.morphologyEx(binary_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# show mask\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(binary_mask, cmap='gray')\n",
        "plt.title(\"Initial Mask using Otsu Thresholding\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# when you want to download the kaggle`s data directly**"
      ],
      "metadata": {
        "id": "IvlR0zDf64Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "sKBwblEr603J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR SHOW E.G DATA**"
      ],
      "metadata": {
        "id": "ctKiY16O7Cu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# the directory of data\n",
        "test_images_path = '/content/valid/Colon_Adenocarcinoma'\n",
        "\n",
        "# selected a image randomly\n",
        "image_files = os.listdir(test_images_path)\n",
        "random_image = image_files[8]\n",
        "\n",
        "# upload the image\n",
        "image_path = os.path.join(test_images_path, random_image)\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# show image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gz1k1FEe7BvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR TRANSFERING DATA**"
      ],
      "metadata": {
        "id": "8uBuOgQR7PIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images_path = '/content/CellNet/CellNet/Colon_Adenocarcinoma'\n",
        "\n",
        "# name of images\n",
        "all_items = os.listdir(images_path)\n",
        "train_path = '/content/train/Colon_Adenocarcinoma'\n",
        "\n",
        "# transfer image to file\n",
        "for item in all_items:\n",
        "    item_path = os.path.join(images_path, item)\n",
        "    # searching for this the file is exsisted\n",
        "    if os.path.isfile(item_path):\n",
        "        shutil.move(item_path, train_path)\n",
        "\n",
        "print(f\"the files transferd\")"
      ],
      "metadata": {
        "id": "tDcfyNfL7OOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM TRANSFER**"
      ],
      "metadata": {
        "id": "rzB0y5TK7XKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "\n",
        "folder1 = \"/content/train/Colon_Benign\"\n",
        "folder2 = \"/content/train/Colon_Adenocarcinoma\"\n",
        "\n",
        "\n",
        "valid_folder1 = \"/content/valid/Colon_Benign\"\n",
        "valid_folder2 = \"/content/valid/Colon_Adenocarcinoma\"\n",
        "test_folder = \"/content/test\"\n",
        "\n",
        "os.makedirs(valid_folder1, exist_ok=True)\n",
        "os.makedirs(valid_folder2, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "def move_random_files(source_folder, destination_folder, percent=10):\n",
        "\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "\n",
        "\n",
        "    num_files_to_move = int(len(files) * percent / 100)\n",
        "\n",
        "\n",
        "    for file in files[:num_files_to_move]:\n",
        "        src_path = os.path.join(source_folder, file)\n",
        "        dest_path = os.path.join(destination_folder, file)\n",
        "\n",
        "\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\": {file} \")\n",
        "\n",
        "\n",
        "move_random_files(folder1, valid_folder1, percent=20)\n",
        "move_random_files(folder2, valid_folder2, percent=20)\n",
        "move_random_files(folder1, test_folder, percent=5)\n",
        "move_random_files(folder2, test_folder, percent=5)\n",
        "print('ok')\n"
      ],
      "metadata": {
        "id": "WlAvDetx7V4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COUNT**"
      ],
      "metadata": {
        "id": "FkoAcuIY7e7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fl_path = '/content/train/Colon_Adenocarcinoma'\n",
        "contents = os.listdir(fl_path)\n",
        "count = len(contents)\n",
        "print(count)"
      ],
      "metadata": {
        "id": "cjW1jK7W7eEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHOWING IMAGEGENERATE DATA**"
      ],
      "metadata": {
        "id": "DWL55Sua7oFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a batch of images and labels using next(train_generator)\n",
        "images, labels = next(train_generator)\n",
        "\n",
        "# Select a random index to display a random image\n",
        "random_index = np.random.randint(0, len(images))  # Choose a random index from the batch\n",
        "\n",
        "# Display the selected image and its label\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(images[random_index])\n",
        "plt.title(f'Label: {labels[random_index]}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TEERn0hT7nTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPLE CNN**"
      ],
      "metadata": {
        "id": "1tHfALeZ7xql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# simple CNN model for binary classification\n",
        "def build_cnn_classifier(input_shape, num_classes=2):\n",
        "    model = models.Sequential([\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Fourth Convolutional Block\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.15),\n",
        "        # Flattening Layer\n",
        "        layers.Flatten(),\n",
        "\n",
        "        # Fully Connected Dense Layers\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(num_classes, activation='softmax')  # Use 'softmax' for binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the input shape and build the model\n",
        "input_shape = (224, 224, 3)\n",
        "model = build_cnn_classifier(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "NVJSLupI7xEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate model with the image**"
      ],
      "metadata": {
        "id": "NLTbyN7_CvaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1.selected file for upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. adjust a image for testing\n",
        "image_path = list(uploaded.keys())[0]\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. preprocessing of image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # the size that model run with it\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "input_image = transform(image).unsqueeze(0)  # batch size\n",
        "\n",
        "# 4. import model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SimpleTransformer().to(device)  # medel\n",
        "model.load_state_dict(torch.load('/content/transformer_model'))  # your directory\n",
        "\n",
        "# 5. the model goes to evaluate and test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_image = input_image.to(device)\n",
        "    output = model(input_image)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    class_names = dataset.classes  # catagory names\n",
        "\n",
        "# 6. result\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted class: {class_names[predicted.item()]}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3ZJac_EZB7xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "K0VNWaCHC6WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), '/content/swin_transformer_model.pth')\n"
      ],
      "metadata": {
        "id": "defyo_XuC5nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load dataset & Split dataset into training and validation sets**"
      ],
      "metadata": {
        "id": "4Le5oGlRJbBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Load dataset\n",
        "data_path = '/content/Colon'  # Update this path with your dataset path\n",
        "dataset = ImageFolder(root=data_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 3.5 Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tZGPdLQpJZe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN MODEL**"
      ],
      "metadata": {
        "id": "Vg7yHc6b74Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data and validate on the test data\n",
        "history = model.fit(\n",
        "    train_generator,  # Training data generator\n",
        "    epochs=5,        # Number of epochs to train the model\n",
        "    validation_data=valid_generator  # Testing data for validation during training\n",
        ")\n"
      ],
      "metadata": {
        "id": "OAgqS5bw73kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REDIUCED RESNET50**"
      ],
      "metadata": {
        "id": "lzLQjJaX7-mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a residual block with bottleneck architecture\n",
        "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
        "    \"\"\"\n",
        "    Defines a residual block with bottleneck architecture.\n",
        "\n",
        "    Args:\n",
        "    - x: Input tensor.\n",
        "    - filters: Number of filters in the bottleneck layer.\n",
        "    - kernel_size: Kernel size for the middle convolution layer.\n",
        "    - stride: Stride size for the first convolution layer.\n",
        "    - conv_shortcut: Whether to use a convolution layer for the shortcut connection.\n",
        "    - name: Name for the block.\n",
        "\n",
        "    Returns:\n",
        "    - Output tensor for the block.\n",
        "    \"\"\"\n",
        "    # Shortcut connection\n",
        "    shortcut = x\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
        "        shortcut = layers.BatchNormalization(name=name + '_0_bn')(shortcut)\n",
        "\n",
        "    # First Convolution Layer\n",
        "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_1_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
        "\n",
        "    # Second Convolution Layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_2_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
        "\n",
        "    # Third Convolution Layer (Projection Layer)\n",
        "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_3_bn')(x)\n",
        "\n",
        "    # Add shortcut to the output\n",
        "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
        "    x = layers.Activation('relu', name=name + '_out')(x)\n",
        "    return x\n",
        "\n",
        "# Define the reduced ResNet-50 architecture\n",
        "def ReducedResNet50(input_shape=(224, 224, 3), num_classes=1000):\n",
        "    \"\"\"\n",
        "    Creates a reduced version of ResNet-50 architecture with fewer blocks.\n",
        "\n",
        "    Args:\n",
        "    - input_shape: Shape of the input tensor.\n",
        "    - num_classes: Number of output classes for classification.\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras model.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution and MaxPooling layer\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding='SAME', name='conv1_conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1_bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same', name='pool1_pool')(x)\n",
        "\n",
        "    # First block group (similar to ResNet-50)\n",
        "    x = residual_block(x, 64, conv_shortcut=True, name='conv2_block1')\n",
        "    x = residual_block(x, 64, conv_shortcut=False, name='conv2_block2')\n",
        "\n",
        "    # Second block group\n",
        "    x = residual_block(x, 128, stride=2, conv_shortcut=True, name='conv3_block1')\n",
        "    x = residual_block(x, 128, conv_shortcut=False, name='conv3_block2')\n",
        "\n",
        "    # Third block group\n",
        "    x = residual_block(x, 256, stride=2, conv_shortcut=True, name='conv4_block1')\n",
        "    x = residual_block(x, 256, conv_shortcut=False, name='conv4_block2')\n",
        "\n",
        "    # Fourth block group\n",
        "    x = residual_block(x, 512, stride=2, conv_shortcut=True, name='conv5_block1')\n",
        "    x = residual_block(x, 512, conv_shortcut=False, name='conv5_block2')\n",
        "\n",
        "    # Global Average Pooling and Classification Layer\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = models.Model(inputs, outputs, name='reduced_resnet50')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the reduced ResNet-50 model\n",
        "reduced_resnet50_model = ReducedResNet50(input_shape=(224, 224, 3), num_classes=2)\n",
        "reduced_resnet50_model.summary()\n"
      ],
      "metadata": {
        "id": "eTEP2h507-Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATED MODEL**"
      ],
      "metadata": {
        "id": "tPVJdIJK8ReL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test data\n",
        "valid_generator.reset()  # Reset the generator to start from the beginning\n",
        "predictions = reduced_resnet50_model.predict(valid_generator)  # Get model predictions\n",
        "\n",
        "# With this line for binary classification (0 or 1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = valid_generator.classes  # Get true class labels from the generator\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=['Colon_Adenocarcinoma', 'Colon_Benign'])\n",
        "print(report)  # Print classification report\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Colon_Adenocarcinoma', 'Colon_Adenocarcinoma'], yticklabels=['Colon_Adenocarcinoma', 'Colon_Benign'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LvsHMO5u8Qxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use all of data just not bach size**"
      ],
      "metadata": {
        "id": "ExiqM8NRmSxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the entire validation data\n",
        "predictions = model.predict(valid_generator, steps=len(valid_generator), verbose=1)\n",
        "\n",
        "# Convert predictions to class indices\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true class labels from the generator\n",
        "true_classes = valid_generator.classes  # Get true labels for all validation samples\n",
        "\n",
        "# Check if the length of predictions and true classes match\n",
        "print(f\"Number of predicted classes: {len(predicted_classes)}\")\n",
        "print(f\"Number of true classes: {len(true_classes)}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n"
      ],
      "metadata": {
        "id": "a04z-XBpmSM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicted with show lable **"
      ],
      "metadata": {
        "id": "9gRJDAVJmc8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of validation data\n",
        "x_val, y_val = next(iter(valid_generator))\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(x_val)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Show misclassified samples\n",
        "misclassified_indices = np.where(predicted_classes != np.argmax(y_val, axis=1))[0]\n",
        "\n",
        "# Plot misclassified images\n",
        "for i, index in enumerate(misclassified_indices[:5]):  # Show only first 5 misclassified samples\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(x_val[index])\n",
        "    plt.title(f\"True: {np.argmax(y_val[index])}, Pr: {predicted_classes[index]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dNte91AimcQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfc2366-d30e-4a32-9248-71f1b4340728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'valid_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ac16eb540d6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get a batch of validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ROC CURVE***"
      ],
      "metadata": {
        "id": "zmEGpa7cmqZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get the predicted probabilities for the positive class (Cancer)\n",
        "pred_probabilities = predictions[:, 1]  # Assuming column 1 corresponds to Cancer class\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(true_classes, pred_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ja0vlzPZmpxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get predicting**"
      ],
      "metadata": {
        "id": "qY0GTGHMmv7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices of misclassified samples\n",
        "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
        "\n",
        "# Print misclassified sample indices and their true vs predicted labels\n",
        "for index in misclassified_indices:\n",
        "    print(f\"Sample index: {index}, True label: {true_classes[index]}, Predicted label: {predicted_classes[index]}\")\n"
      ],
      "metadata": {
        "id": "UmPASNKlmvi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PLOT FOR TRAINING LOSS AND VALID LOSS**"
      ],
      "metadata": {
        "id": "sbqULaoWm419"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GZUJri70m4IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Visualize training & validation loss and accuracy**"
      ],
      "metadata": {
        "id": "w3_kGkvsGizl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qLryub8pGgPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC CURVE**"
      ],
      "metadata": {
        "id": "j9GI10MOHEwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get the predicted probabilities for the positive class (Cancer)\n",
        "pred_probabilities = predictions[:, 1]  # Assuming column 1 corresponds to Cancer class\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(true_classes, pred_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1O4QFshaG-9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Transfering a FIle**"
      ],
      "metadata": {
        "id": "azbOZFZ9F-Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# transfer folders\n",
        "source_folder = 'Colon_Adenocarcinoma'\n",
        "destination_folder = '/content/Colon'\n",
        "shutil.move(source_folder, destination_folder)\n",
        "print('moved')"
      ],
      "metadata": {
        "id": "be39NHl_F7YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import model **"
      ],
      "metadata": {
        "id": "G5IkN3GQS481"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "\n",
        "# Define the same model architecture\n",
        "model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=False, num_classes=2)\n",
        "model.load_state_dict(torch.load('swin_transformer_model.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "zkaf2BVIS1s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN MODEL WITH TEST IMAGE"
      ],
      "metadata": {
        "id": "ZFatCbzkTAfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the same image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load an image\n",
        "image_path = 'path_to_your_image.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Apply the transformations\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(image_tensor)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "print(f'Predicted class: {predicted_class.item()}')\n"
      ],
      "metadata": {
        "id": "O5OLeyukS4B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Grad-CAM"
      ],
      "metadata": {
        "id": "ZwhWsbn9_5Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from timm import create_model\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 1. Dataset definition for MIL (Each image is a \"bag\", and patches are instances)\n",
        "class CancerMIL(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, patch_size=16):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.patch_size = patch_size\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for label, folder in enumerate(['Colon_Benign', 'Colon_Adenocarcinoma']):\n",
        "            folder_path = os.path.join(root_dir, folder)\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                self.image_paths.append(img_path)\n",
        "                self.labels.append(label)  # 0 for Colon_Benign, 1 for Colon_Adenocarcinoma\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Divide image into patches\n",
        "        patches = []\n",
        "        width, height = image.size\n",
        "        for i in range(0, width, self.patch_size):\n",
        "            for j in range(0, height, self.patch_size):\n",
        "                patch = image.crop((i, j, i + self.patch_size, j + self.patch_size))\n",
        "                if self.transform:\n",
        "                    patch = self.transform(patch)\n",
        "                patches.append(patch)\n",
        "\n",
        "        return torch.stack(patches), label\n",
        "\n",
        "# 2. Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust based on your patch size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 3. Define the dataset and dataloader\n",
        "# Create the dataset instance first\n",
        "dataset = CancerMIL(root_dir='/content/Colon', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)  # Bag-level batch size\n",
        "\n",
        "# 3.5 Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 4. Define the MIL model using Swin Transformer\n",
        "class MILModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MILModel, self).__init__()\n",
        "        self.swin = create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=1)  # Use a smaller model\n",
        "        self.classifier = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        instance_predictions = []\n",
        "        # Process patches in smaller batches\n",
        "        for i in range(0, x.squeeze(0).shape[0], 16):  # Reduced batch to 16 patches at a time\n",
        "            batch_patches = x.squeeze(0)[i:i + 16]\n",
        "            instance_pred = self.swin(batch_patches)\n",
        "            instance_predictions.append(instance_pred)\n",
        "\n",
        "        instance_predictions = torch.cat(instance_predictions, dim=0)\n",
        "        bag_prediction = torch.max(instance_predictions)\n",
        "\n",
        "        return bag_prediction\n",
        "\n",
        "\n",
        "# 5. Loss function and optimizer\n",
        "model = MILModel().to('cuda')\n",
        "criterion = nn.BCEWithLogitsLoss()  # For binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 6. Training loop for MIL\n",
        "for epoch in range(3):\n",
        "    for i, (patches, label) in enumerate(train_loader):\n",
        "        patches, label = patches.to('cuda'), label.float().to('cuda')\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(patches)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        # Scale loss for gradient accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights every accumulation_steps\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/3], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "l2IAVAjo_3Xz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}