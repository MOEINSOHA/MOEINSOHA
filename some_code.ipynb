{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ1Gvr4HMEW8RHa6+PdWVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOEINSOHA/MOEINSOHA/blob/main/some_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR MASK ALGORITHM**"
      ],
      "metadata": {
        "id": "VIDMqmnT6cpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0dXzza76Tho"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# upload image\n",
        "input_image_path = \"/content/CellNet/CellNet/Breast_Malignant/SOB_M_DC-14-10926-400-002.png\"\n",
        "image = cv2.imread(input_image_path, 0)  # gray scale\"\n",
        "\n",
        "# OtsuThresholding alogorithm adjust mask\n",
        "thresh_value = threshold_otsu(image)\n",
        "binary_mask = image > thresh_value\n",
        "\n",
        "# use morphologhic data\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "binary_mask = cv2.morphologyEx(binary_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# show mask\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(binary_mask, cmap='gray')\n",
        "plt.title(\"Initial Mask using Otsu Thresholding\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# when you want to download the kaggle`s data directly**"
      ],
      "metadata": {
        "id": "IvlR0zDf64Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "sKBwblEr603J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR SHOW E.G DATA**"
      ],
      "metadata": {
        "id": "ctKiY16O7Cu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# the directory of data\n",
        "test_images_path = '/content/valid/Colon_Adenocarcinoma'\n",
        "\n",
        "# selected a image randomly\n",
        "image_files = os.listdir(test_images_path)\n",
        "random_image = image_files[8]\n",
        "\n",
        "# upload the image\n",
        "image_path = os.path.join(test_images_path, random_image)\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# show image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gz1k1FEe7BvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR TRANSFERING DATA**"
      ],
      "metadata": {
        "id": "8uBuOgQR7PIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images_path = '/content/CellNet/CellNet/Colon_Adenocarcinoma'\n",
        "\n",
        "# name of images\n",
        "all_items = os.listdir(images_path)\n",
        "train_path = '/content/train/Colon_Adenocarcinoma'\n",
        "\n",
        "# transfer image to file\n",
        "for item in all_items:\n",
        "    item_path = os.path.join(images_path, item)\n",
        "    # searching for this the file is exsisted\n",
        "    if os.path.isfile(item_path):\n",
        "        shutil.move(item_path, train_path)\n",
        "\n",
        "print(f\"the files transferd\")"
      ],
      "metadata": {
        "id": "tDcfyNfL7OOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM TRANSFER**"
      ],
      "metadata": {
        "id": "rzB0y5TK7XKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "\n",
        "folder1 = \"/content/train/Colon_Benign\"\n",
        "folder2 = \"/content/train/Colon_Adenocarcinoma\"\n",
        "\n",
        "\n",
        "valid_folder1 = \"/content/valid/Colon_Benign\"\n",
        "valid_folder2 = \"/content/valid/Colon_Adenocarcinoma\"\n",
        "test_folder = \"/content/test\"\n",
        "\n",
        "os.makedirs(valid_folder1, exist_ok=True)\n",
        "os.makedirs(valid_folder2, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "def move_random_files(source_folder, destination_folder, percent=10):\n",
        "\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "\n",
        "\n",
        "    num_files_to_move = int(len(files) * percent / 100)\n",
        "\n",
        "\n",
        "    for file in files[:num_files_to_move]:\n",
        "        src_path = os.path.join(source_folder, file)\n",
        "        dest_path = os.path.join(destination_folder, file)\n",
        "\n",
        "\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\": {file} \")\n",
        "\n",
        "\n",
        "move_random_files(folder1, valid_folder1, percent=20)\n",
        "move_random_files(folder2, valid_folder2, percent=20)\n",
        "move_random_files(folder1, test_folder, percent=5)\n",
        "move_random_files(folder2, test_folder, percent=5)\n",
        "print('ok')\n"
      ],
      "metadata": {
        "id": "WlAvDetx7V4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COUNT**"
      ],
      "metadata": {
        "id": "FkoAcuIY7e7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fl_path = '/content/train/Colon_Adenocarcinoma'\n",
        "contents = os.listdir(fl_path)\n",
        "count = len(contents)\n",
        "print(count)"
      ],
      "metadata": {
        "id": "cjW1jK7W7eEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHOWING IMAGEGENERATE DATA**"
      ],
      "metadata": {
        "id": "DWL55Sua7oFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a batch of images and labels using next(train_generator)\n",
        "images, labels = next(train_generator)\n",
        "\n",
        "# Select a random index to display a random image\n",
        "random_index = np.random.randint(0, len(images))  # Choose a random index from the batch\n",
        "\n",
        "# Display the selected image and its label\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(images[random_index])\n",
        "plt.title(f'Label: {labels[random_index]}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TEERn0hT7nTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPLE CNN**"
      ],
      "metadata": {
        "id": "1tHfALeZ7xql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# simple CNN model for binary classification\n",
        "def build_cnn_classifier(input_shape, num_classes=2):\n",
        "    model = models.Sequential([\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # Fourth Convolutional Block\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.15),\n",
        "        # Flattening Layer\n",
        "        layers.Flatten(),\n",
        "\n",
        "        # Fully Connected Dense Layers\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(num_classes, activation='softmax')  # Use 'softmax' for binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the input shape and build the model\n",
        "input_shape = (224, 224, 3)\n",
        "model = build_cnn_classifier(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "NVJSLupI7xEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN MODEL**"
      ],
      "metadata": {
        "id": "Vg7yHc6b74Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data and validate on the test data\n",
        "history = model.fit(\n",
        "    train_generator,  # Training data generator\n",
        "    epochs=5,        # Number of epochs to train the model\n",
        "    validation_data=valid_generator  # Testing data for validation during training\n",
        ")\n"
      ],
      "metadata": {
        "id": "OAgqS5bw73kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REDIUCED RESNET50**"
      ],
      "metadata": {
        "id": "lzLQjJaX7-mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a residual block with bottleneck architecture\n",
        "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
        "    \"\"\"\n",
        "    Defines a residual block with bottleneck architecture.\n",
        "\n",
        "    Args:\n",
        "    - x: Input tensor.\n",
        "    - filters: Number of filters in the bottleneck layer.\n",
        "    - kernel_size: Kernel size for the middle convolution layer.\n",
        "    - stride: Stride size for the first convolution layer.\n",
        "    - conv_shortcut: Whether to use a convolution layer for the shortcut connection.\n",
        "    - name: Name for the block.\n",
        "\n",
        "    Returns:\n",
        "    - Output tensor for the block.\n",
        "    \"\"\"\n",
        "    # Shortcut connection\n",
        "    shortcut = x\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
        "        shortcut = layers.BatchNormalization(name=name + '_0_bn')(shortcut)\n",
        "\n",
        "    # First Convolution Layer\n",
        "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_1_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
        "\n",
        "    # Second Convolution Layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_2_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
        "\n",
        "    # Third Convolution Layer (Projection Layer)\n",
        "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
        "    x = layers.BatchNormalization(name=name + '_3_bn')(x)\n",
        "\n",
        "    # Add shortcut to the output\n",
        "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
        "    x = layers.Activation('relu', name=name + '_out')(x)\n",
        "    return x\n",
        "\n",
        "# Define the reduced ResNet-50 architecture\n",
        "def ReducedResNet50(input_shape=(224, 224, 3), num_classes=1000):\n",
        "    \"\"\"\n",
        "    Creates a reduced version of ResNet-50 architecture with fewer blocks.\n",
        "\n",
        "    Args:\n",
        "    - input_shape: Shape of the input tensor.\n",
        "    - num_classes: Number of output classes for classification.\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras model.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution and MaxPooling layer\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding='SAME', name='conv1_conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1_bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same', name='pool1_pool')(x)\n",
        "\n",
        "    # First block group (similar to ResNet-50)\n",
        "    x = residual_block(x, 64, conv_shortcut=True, name='conv2_block1')\n",
        "    x = residual_block(x, 64, conv_shortcut=False, name='conv2_block2')\n",
        "\n",
        "    # Second block group\n",
        "    x = residual_block(x, 128, stride=2, conv_shortcut=True, name='conv3_block1')\n",
        "    x = residual_block(x, 128, conv_shortcut=False, name='conv3_block2')\n",
        "\n",
        "    # Third block group\n",
        "    x = residual_block(x, 256, stride=2, conv_shortcut=True, name='conv4_block1')\n",
        "    x = residual_block(x, 256, conv_shortcut=False, name='conv4_block2')\n",
        "\n",
        "    # Fourth block group\n",
        "    x = residual_block(x, 512, stride=2, conv_shortcut=True, name='conv5_block1')\n",
        "    x = residual_block(x, 512, conv_shortcut=False, name='conv5_block2')\n",
        "\n",
        "    # Global Average Pooling and Classification Layer\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = models.Model(inputs, outputs, name='reduced_resnet50')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the reduced ResNet-50 model\n",
        "reduced_resnet50_model = ReducedResNet50(input_shape=(224, 224, 3), num_classes=2)\n",
        "reduced_resnet50_model.summary()\n"
      ],
      "metadata": {
        "id": "eTEP2h507-Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATED MODEL**"
      ],
      "metadata": {
        "id": "tPVJdIJK8ReL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test data\n",
        "valid_generator.reset()  # Reset the generator to start from the beginning\n",
        "predictions = reduced_resnet50_model.predict(valid_generator)  # Get model predictions\n",
        "\n",
        "# With this line for binary classification (0 or 1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = valid_generator.classes  # Get true class labels from the generator\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=['Colon_Adenocarcinoma', 'Colon_Benign'])\n",
        "print(report)  # Print classification report\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Colon_Adenocarcinoma', 'Colon_Adenocarcinoma'], yticklabels=['Colon_Adenocarcinoma', 'Colon_Benign'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LvsHMO5u8Qxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use all of data just not bach size**"
      ],
      "metadata": {
        "id": "ExiqM8NRmSxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the entire validation data\n",
        "predictions = model.predict(valid_generator, steps=len(valid_generator), verbose=1)\n",
        "\n",
        "# Convert predictions to class indices\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true class labels from the generator\n",
        "true_classes = valid_generator.classes  # Get true labels for all validation samples\n",
        "\n",
        "# Check if the length of predictions and true classes match\n",
        "print(f\"Number of predicted classes: {len(predicted_classes)}\")\n",
        "print(f\"Number of true classes: {len(true_classes)}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n"
      ],
      "metadata": {
        "id": "a04z-XBpmSM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicted with show lable **"
      ],
      "metadata": {
        "id": "9gRJDAVJmc8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of validation data\n",
        "x_val, y_val = next(iter(valid_generator))\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(x_val)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Show misclassified samples\n",
        "misclassified_indices = np.where(predicted_classes != np.argmax(y_val, axis=1))[0]\n",
        "\n",
        "# Plot misclassified images\n",
        "for i, index in enumerate(misclassified_indices[:5]):  # Show only first 5 misclassified samples\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(x_val[index])\n",
        "    plt.title(f\"True: {np.argmax(y_val[index])}, Pr: {predicted_classes[index]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dNte91AimcQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ROC CURVE***"
      ],
      "metadata": {
        "id": "zmEGpa7cmqZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get the predicted probabilities for the positive class (Cancer)\n",
        "pred_probabilities = predictions[:, 1]  # Assuming column 1 corresponds to Cancer class\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(true_classes, pred_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ja0vlzPZmpxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get predicting**"
      ],
      "metadata": {
        "id": "qY0GTGHMmv7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices of misclassified samples\n",
        "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
        "\n",
        "# Print misclassified sample indices and their true vs predicted labels\n",
        "for index in misclassified_indices:\n",
        "    print(f\"Sample index: {index}, True label: {true_classes[index]}, Predicted label: {predicted_classes[index]}\")\n"
      ],
      "metadata": {
        "id": "UmPASNKlmvi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PLOT FOR TRAINING LOSS AND VALID LOSS**"
      ],
      "metadata": {
        "id": "sbqULaoWm419"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GZUJri70m4IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Visualize training & validation loss and accuracy**"
      ],
      "metadata": {
        "id": "w3_kGkvsGizl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qLryub8pGgPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC CURVE**"
      ],
      "metadata": {
        "id": "j9GI10MOHEwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get the predicted probabilities for the positive class (Cancer)\n",
        "pred_probabilities = predictions[:, 1]  # Assuming column 1 corresponds to Cancer class\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(true_classes, pred_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1O4QFshaG-9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Transfering a FIle**"
      ],
      "metadata": {
        "id": "azbOZFZ9F-Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# transfer folders\n",
        "source_folder = 'Colon_Adenocarcinoma'\n",
        "destination_folder = '/content/Colon'\n",
        "shutil.move(source_folder, destination_folder)\n",
        "print('moved')"
      ],
      "metadata": {
        "id": "be39NHl_F7YY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}